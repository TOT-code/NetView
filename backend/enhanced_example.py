"""
å¢å¼ºå‹æ¨¡å‹è§£æå™¨ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºåŠ¨æ€å›¾ã€æ¶æ„æ¨¡å¼å’Œtensoræµåˆ†æçš„å®Œæ•´åŠŸèƒ½
"""

import sys
import os
import torch
import torch.nn as nn
import json

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.modules.parser import EnhancedModelExtractor
from examples.simple_cnn import SimpleCNN

def demonstrate_enhanced_features():
    """æ¼”ç¤ºå¢å¼ºåŠŸèƒ½"""
    print("ğŸš€ NetView å¢å¼ºå‹æ¨¡å‹è§£æå™¨æ¼”ç¤º")
    print("ç‰ˆæœ¬: 0.2.0 (å¢å¼ºç‰ˆ)")
    print("æ–°å¢åŠŸèƒ½: åŠ¨æ€å›¾åˆ†æã€æ¶æ„æ¨¡å¼è¯†åˆ«ã€Tensoræµè¿½è¸ª")
    print("=" * 80)
    
    # åˆ›å»ºå¢å¼ºå‹æå–å™¨
    extractor = EnhancedModelExtractor()
    
    # 1. åŸºç¡€æ¨¡å‹çš„å¢å¼ºåˆ†æ
    print("\nğŸ” 1. åŸºç¡€æ¨¡å‹å¢å¼ºåˆ†æ")
    print("-" * 60)
    
    model = SimpleCNN(num_classes=10)
    enhanced_info = extractor.extract_from_model(model, input_shape=(1, 3, 32, 32))
    
    print(f"âœ“ æ¨¡å‹åç§°: {enhanced_info.model_name}")
    print(f"âœ“ æ¶æ„ç±»å‹: {enhanced_info.network_graph.graph_type}")
    print(f"âœ“ åŸºç¡€ç»“æ„: {len(enhanced_info.network_graph.nodes)} èŠ‚ç‚¹, {len(enhanced_info.network_graph.edges)} è¿æ¥")
    
    # åŠ¨æ€åˆ†æç»“æœ
    if enhanced_info.dynamic_analysis:
        print(f"ğŸ”„ åŠ¨æ€åˆ†æ:")
        print(f"  - åŠ¨æ€æ§åˆ¶: {enhanced_info.dynamic_analysis.has_dynamic_control}")
        print(f"  - æ‰§è¡Œè·¯å¾„: {len(enhanced_info.dynamic_analysis.execution_paths)}")
        print(f"  - åŠ¨æ€æ“ä½œ: {len(enhanced_info.dynamic_analysis.dynamic_operations)}")
    
    # æ¶æ„æ¨¡å¼ç»“æœ
    if enhanced_info.architecture_patterns:
        print(f"ğŸ—ï¸ æ¶æ„æ¨¡å¼:")
        patterns = enhanced_info.architecture_patterns
        print(f"  - æ¨¡å¼ç±»å‹: {patterns.pattern_type}")
        print(f"  - æ®‹å·®è¿æ¥: {len(patterns.residual_connections)}")
        print(f"  - å¯†é›†è¿æ¥: {len(patterns.dense_connections)}")
        print(f"  - æ³¨æ„åŠ›æ¨¡å¼: {len(patterns.attention_patterns)}")
        print(f"  - åˆ†æ”¯ç‚¹: {len(patterns.branch_points)}")
        print(f"  - åˆå¹¶ç‚¹: {len(patterns.merge_points)}")
    
    # Tensoræµåˆ†æç»“æœ
    if enhanced_info.tensor_flow_analysis:
        print(f"ğŸ“Š Tensoræµåˆ†æ:")
        tensor_flow = enhanced_info.tensor_flow_analysis
        print(f"  - Tensoræ“ä½œ: {len(tensor_flow.tensor_operations)}")
        print(f"  - æ•°æ®æµè·¯å¾„: {len(tensor_flow.data_flow_paths)}")
        print(f"  - è·¯ç”±ä¿¡æ¯: {len(tensor_flow.routing_info)}")
        print(f"  - å½¢çŠ¶å˜åŒ–è®°å½•: {len(tensor_flow.shape_changes)}")
        print(f"  - æ•°æ®ä¾èµ–: {len(tensor_flow.data_dependencies)}")
    
    # 2. åˆ›å»ºåŒ…å«ResNetå—çš„æ¨¡å‹
    print("\nğŸ—ï¸ 2. ResNetæ¶æ„æ¨¡å¼è¯†åˆ«")
    print("-" * 60)
    
    resnet_code = """
import torch
import torch.nn as nn

class MiniResNet(nn.Module):
    def __init__(self, num_classes=10):
        super(MiniResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.shortcut = nn.Conv2d(64, 128, 1)
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(128, num_classes)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        # ç¬¬ä¸€å±‚
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        # æ®‹å·®å—
        identity = out
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        
        out = self.conv3(out)
        out = self.bn3(out)
        
        # æ®‹å·®è¿æ¥ - å…³é”®ç‰¹å¾
        identity = self.shortcut(identity)
        out = out + identity
        out = self.relu(out)
        
        # åˆ†ç±»å±‚
        out = self.pool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        
        return out
"""
    
    resnet_info = extractor.extract_from_code(resnet_code, input_shape=(1, 3, 32, 32))
    
    print(f"âœ“ è¯†åˆ«æ¨¡å‹: {resnet_info.model_name}")
    print(f"âœ“ æ¶æ„ç±»å‹: {resnet_info.network_graph.graph_type}")
    
    if resnet_info.architecture_patterns:
        patterns = resnet_info.architecture_patterns
        print(f"ğŸ¯ ResNetæ¨¡å¼è¯†åˆ«:")
        print(f"  - æ£€æµ‹åˆ°æ¶æ„: {patterns.pattern_type}")
        print(f"  - æ®‹å·®è¿æ¥æ•°: {len(patterns.residual_connections)}")
        
        for i, conn in enumerate(patterns.residual_connections):
            print(f"    æ®‹å·®è¿æ¥{i+1}: {conn.input_layer} -> {conn.output_layer}")
            if conn.shortcut_layer:
                print(f"      shortcut: {conn.shortcut_layer}")
    
    # 3. åŠ¨æ€æ§åˆ¶æµåˆ†æ
    print("\nğŸ”„ 3. åŠ¨æ€æ§åˆ¶æµåˆ†æ")
    print("-" * 60)
    
    dynamic_code = """
import torch
import torch.nn as nn

class AdaptiveNet(nn.Module):
    def __init__(self, num_classes=10):
        super(AdaptiveNet, self).__init__()
        self.conv_layers = nn.ModuleList([
            nn.Conv2d(3, 32, 3, padding=1),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.Conv2d(64, 128, 3, padding=1)
        ])
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(0.5)
        
    def forward(self, x):
        # åŠ¨æ€é€‰æ‹©å±‚æ•°
        for i, layer in enumerate(self.conv_layers):
            x = layer(x)
            x = torch.relu(x)
            
            # æ¡ä»¶æ€§dropout
            if self.training and i > 0:
                x = self.dropout(x)
            
            # åŠ¨æ€æ± åŒ–
            if x.size(2) > 8:  # å¦‚æœç‰¹å¾å›¾å¤ªå¤§
                x = torch.nn.functional.max_pool2d(x, 2)
        
        # è‡ªé€‚åº”å¤„ç†
        x = self.adaptive_pool(x)
        x = x.view(x.size(0), -1)
        
        # åŠ¨æ€è°ƒæ•´ç‰¹å¾ç»´åº¦
        if x.size(1) != 128:
            # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´
            if x.size(1) > 128:
                x = x[:, :128]
            else:
                padding = torch.zeros(x.size(0), 128 - x.size(1), device=x.device)
                x = torch.cat([x, padding], dim=1)
        
        x = self.classifier(x)
        return x
"""
    
    dynamic_info = extractor.extract_from_code(dynamic_code, input_shape=(1, 3, 64, 64))
    
    print(f"âœ“ æ¨¡å‹åç§°: {dynamic_info.model_name}")
    
    if dynamic_info.dynamic_analysis:
        dynamic = dynamic_info.dynamic_analysis
        print(f"ğŸ”„ åŠ¨æ€ç‰¹å¾æ£€æµ‹:")
        print(f"  - åŠ¨æ€æ§åˆ¶: {dynamic.has_dynamic_control}")
        print(f"  - æ§åˆ¶æµèŠ‚ç‚¹: {len(dynamic.control_flow_nodes)}")
        print(f"  - æ‰§è¡Œè·¯å¾„: {len(dynamic.execution_paths)}")
        print(f"  - åŠ¨æ€æ“ä½œ: {len(dynamic.dynamic_operations)}")
        
        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„åŠ¨æ€æ“ä½œ
        for i, op in enumerate(dynamic.dynamic_operations[:5]):
            op_type = op.get('type', 'unknown')
            match = op.get('match', '')
            print(f"    åŠ¨æ€æ“ä½œ{i+1}: {op_type} - {match[:50]}...")
    
    # 4. Tensoræ“ä½œè¿½è¸ª
    print("\nğŸ“Š 4. Tensoræ“ä½œæµè¿½è¸ª")
    print("-" * 60)
    
    tensor_ops_code = """
import torch
import torch.nn as nn

class MultiPathNet(nn.Module):
    def __init__(self):
        super(MultiPathNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.conv2a = nn.Conv2d(32, 32, 3, padding=1)
        self.conv2b = nn.Conv2d(32, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.fc = nn.Linear(128, 10)
        
    def forward(self, x):
        # åŸºç¡€å·ç§¯
        x = self.conv1(x)
        x = torch.relu(x)
        
        # åˆ†æ”¯å¤„ç†
        x1, x2 = torch.split(x, 32, dim=1)  # Splitæ“ä½œ
        
        # å¹¶è¡Œå¤„ç†è·¯å¾„
        x1 = self.conv2a(x1)
        x1 = torch.relu(x1)
        
        x2 = self.conv2b(x2)
        x2 = torch.sigmoid(x2)
        
        # åˆå¹¶è·¯å¾„
        x = torch.cat([x1, x2], dim=1)  # Concatæ“ä½œ
        
        # è¿›ä¸€æ­¥å¤„ç†
        x = self.conv3(x)
        x = torch.relu(x)
        
        # å½¢çŠ¶å˜æ¢
        x = x.view(x.size(0), x.size(1), -1)  # Reshape
        x = x.mean(dim=2)  # é™ç»´
        
        # å¦‚æœéœ€è¦ï¼Œè¿›è¡Œè½¬ç½®
        if len(x.shape) > 2:
            x = x.transpose(1, 2)
        
        x = self.fc(x)
        return x
"""
    
    tensor_info = extractor.extract_from_code(tensor_ops_code, input_shape=(1, 3, 32, 32))
    
    print(f"âœ“ æ¨¡å‹åç§°: {tensor_info.model_name}")
    
    if tensor_info.tensor_flow_analysis:
        tensor_flow = tensor_info.tensor_flow_analysis
        print(f"ğŸ“Š Tensoræ“ä½œåˆ†æ:")
        print(f"  - æ€»æ“ä½œæ•°: {len(tensor_flow.tensor_operations)}")
        print(f"  - æ•°æ®æµè·¯å¾„: {len(tensor_flow.data_flow_paths)}")
        print(f"  - è·¯ç”±èŠ‚ç‚¹: {len(tensor_flow.routing_info)}")
        
        # æ˜¾ç¤ºä¸»è¦æ“ä½œç±»å‹
        op_types = {}
        for op in tensor_flow.tensor_operations:
            op_types[op.op_type] = op_types.get(op.op_type, 0) + 1
        
        print(f"  ğŸ“‹ æ“ä½œç±»å‹ç»Ÿè®¡:")
        for op_type, count in op_types.items():
            print(f"    {op_type}: {count}ä¸ª")
        
        # æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯
        print(f"  ğŸ”€ æ•°æ®è·¯ç”±:")
        for i, routing in enumerate(tensor_flow.routing_info):
            print(f"    è·¯ç”±{i+1}: {routing.routing_type}")
            print(f"      è¾“å…¥: {routing.input_tensor}")
            print(f"      è¾“å‡º: {routing.output_tensors}")
    
    # 5. ç”Ÿæˆå®Œæ•´çš„å¢å¼ºå¯è§†åŒ–æ•°æ®
    print("\nğŸ“ˆ 5. å¢å¼ºå¯è§†åŒ–æ•°æ®ç”Ÿæˆ")
    print("-" * 60)
    
    viz_data = extractor.get_enhanced_visualization_data(enhanced_info)
    
    print(f"âœ“ ç”Ÿæˆå¢å¼ºå¯è§†åŒ–æ•°æ®:")
    print(f"  ğŸ“Š åŸºç¡€å›¾ç»“æ„:")
    print(f"    - èŠ‚ç‚¹: {len(viz_data['nodes'])}")
    print(f"    - è¾¹: {len(viz_data['edges'])}")
    print(f"    - è¾“å…¥èŠ‚ç‚¹: {viz_data['metadata']['input_nodes']}")
    print(f"    - è¾“å‡ºèŠ‚ç‚¹: {viz_data['metadata']['output_nodes']}")
    
    if 'dynamic_info' in viz_data:
        dynamic_viz = viz_data['dynamic_info']
        print(f"  ğŸ”„ åŠ¨æ€åˆ†ææ•°æ®:")
        print(f"    - æ˜¯å¦åŠ¨æ€: {dynamic_viz['is_dynamic']}")
        print(f"    - æ§åˆ¶æµèŠ‚ç‚¹: {len(dynamic_viz['control_flow_nodes'])}")
        print(f"    - æ‰§è¡Œè·¯å¾„: {len(dynamic_viz['execution_paths'])}")
    
    if 'architecture_patterns' in viz_data:
        arch_viz = viz_data['architecture_patterns']
        print(f"  ğŸ—ï¸ æ¶æ„æ¨¡å¼æ•°æ®:")
        print(f"    - æ¶æ„ç±»å‹: {arch_viz['architecture_type']}")
        print(f"    - æ®‹å·®è¿æ¥: {len(arch_viz['residual_connections'])}")
        print(f"    - åˆ†æ”¯ç‚¹: {len(arch_viz['branch_points'])}")
        print(f"    - åˆå¹¶ç‚¹: {len(arch_viz['merge_points'])}")
    
    if 'tensor_flow' in viz_data:
        tensor_viz = viz_data['tensor_flow']
        print(f"  ğŸ“Š Tensoræµæ•°æ®:")
        print(f"    - Tensoræ“ä½œ: {len(tensor_viz['tensor_operations'])}")
        print(f"    - æ•°æ®æµè·¯å¾„: {len(tensor_viz['data_flow_paths'])}")
        print(f"    - è·¯ç”±ä¿¡æ¯: {len(tensor_viz['routing_info'])}")
    
    # 6. ä¿å­˜å¢å¼ºåˆ†æç»“æœ
    print("\nğŸ’¾ 6. ä¿å­˜å¢å¼ºåˆ†æç»“æœ")
    print("-" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('output', exist_ok=True)
    
    # ä¿å­˜å¢å¼ºåˆ†æç»“æœ
    enhanced_result = extractor.to_dict(enhanced_info)
    with open('output/enhanced_model_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(enhanced_result, f, indent=2, ensure_ascii=False, default=str)
    
    # ä¿å­˜å¢å¼ºå¯è§†åŒ–æ•°æ®
    with open('output/enhanced_visualization_data.json', 'w', encoding='utf-8') as f:
        json.dump(viz_data, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"âœ“ ä¿å­˜å®Œæˆ:")
    print(f"  - å®Œæ•´åˆ†æç»“æœ: output/enhanced_model_analysis.json")
    print(f"  - å¯è§†åŒ–æ•°æ®: output/enhanced_visualization_data.json")
    
    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
    analysis_size = os.path.getsize('output/enhanced_model_analysis.json')
    viz_size = os.path.getsize('output/enhanced_visualization_data.json')
    print(f"  - åˆ†ææ–‡ä»¶å¤§å°: {analysis_size:,} bytes")
    print(f"  - å¯è§†åŒ–æ–‡ä»¶å¤§å°: {viz_size:,} bytes")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ å¢å¼ºå‹æ¨¡å‹è§£æå™¨æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    
    print("\nğŸš€ å¢å¼ºåŠŸèƒ½æ€»ç»“:")
    print("âœ… åŠ¨æ€å›¾åˆ†æ - æ£€æµ‹æ¡ä»¶åˆ†æ”¯ã€å¾ªç¯å’ŒåŠ¨æ€å½¢çŠ¶å˜åŒ–")
    print("âœ… æ¶æ„æ¨¡å¼è¯†åˆ« - è‡ªåŠ¨è¯†åˆ«ResNetã€DenseNetã€Transformerç­‰æ¶æ„")
    print("âœ… Tensoræµè¿½è¸ª - è¯¦ç»†åˆ†ætensorçš„splitã€concatã€reshapeç­‰æ“ä½œ")
    print("âœ… å¢å¼ºå¯è§†åŒ– - æä¾›æ›´ä¸°å¯Œçš„å›¾å½¢åŒ–æ•°æ®")
    print("âœ… æ™ºèƒ½è¿æ¥æ£€æµ‹ - è¯†åˆ«æ®‹å·®è¿æ¥ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰å¤æ‚è¿æ¥æ¨¡å¼")
    print("âœ… å®Œæ•´æ•°æ®å¯¼å‡º - æ”¯æŒJSONæ ¼å¼çš„è¯¦ç»†åˆ†æç»“æœ")
    
    print("\nğŸ“‹ æ”¯æŒçš„æ–°ç‰¹æ€§:")
    print("  ğŸ”„ åŠ¨æ€æ§åˆ¶æµ: ifè¯­å¥ã€forå¾ªç¯ã€whileå¾ªç¯")
    print("  ğŸ—ï¸ æ¶æ„æ¨¡å¼: ResNetã€DenseNetã€Transformerã€U-Net")
    print("  ğŸ“Š Tensoræ“ä½œ: viewã€reshapeã€splitã€catã€permuteã€transpose")
    print("  ğŸ”€ æ•°æ®è·¯ç”±: splitåˆ†å‘ã€concatèšåˆã€å¹¿æ’­ã€æ”¶é›†")
    print("  ğŸ¯ æ™ºèƒ½è¯†åˆ«: è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹å’Œå¤æ‚è¿æ¥å…³ç³»")

def main():
    """ä¸»å‡½æ•°"""
    try:
        demonstrate_enhanced_features()
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
